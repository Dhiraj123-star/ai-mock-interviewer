import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")
if not openai_key:
    st.error("âŒ OPENAI_API_KEY not found in environment. Please add it to .env file.")
    st.stop()

client = OpenAI(api_key=openai_key)

# Streamlit setup
st.set_page_config(page_title="ğŸ¤– AI Mock Interviewer", page_icon="ğŸ§ ", layout="centered")
st.title("ğŸ¤– AI Mock Interviewer")
st.markdown("An **AI-powered live mock interviewer** tailored to your topic, experience, and difficulty level.")

# Initialize session state
if "current_question" not in st.session_state:
    st.session_state.current_question = None
if "answer_submitted" not in st.session_state:
    st.session_state.answer_submitted = False
if "interview_over" not in st.session_state:
    st.session_state.interview_over = False
if "transcript" not in st.session_state:
    st.session_state.transcript = ""
if "question_count" not in st.session_state:
    st.session_state.question_count = 0

# ğŸ§  Collect User Preferences
st.sidebar.header("âš™ï¸ Interview Settings")
topic = st.sidebar.text_input("ğŸ¯ Interview Topic:", "Python")
experience_level = st.sidebar.selectbox("ğŸ’¼ Experience Level:", ["Beginner", "Intermediate", "Expert"])
difficulty = st.sidebar.selectbox("ğŸ”¥ Question Difficulty:", ["Easy", "Medium", "Hard"])
total_questions = st.sidebar.number_input("ğŸ§© Number of Questions:", min_value=1, max_value=10, value=5, step=1)

# ğŸ§© Generate question dynamically
def generate_question(topic, exp_level, difficulty, prev_qs):
    prompt = (
        f"You are an expert interviewer conducting a {difficulty.lower()}-level mock interview "
        f"for a {exp_level.lower()} {topic} developer.\n"
        f"Previous questions: {prev_qs}\n"
        f"Ask the next non-repetitive, high-quality interview question.\n"
        f"Return only the question text."
    )
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )
    return response.choices[0].message.content.strip()

# ğŸ§© Evaluate candidate answer
def evaluate_answer(question, answer, exp_level):
    prompt = (
        f"You are a senior interviewer evaluating a {exp_level.lower()}-level candidate.\n"
        f"Question: {question}\n"
        f"Candidate Answer: {answer}\n\n"
        "Provide feedback with:\n"
        "1ï¸âƒ£ Accuracy assessment\n"
        "2ï¸âƒ£ Strengths in the answer\n"
        "3ï¸âƒ£ Areas for improvement\n"
        "4ï¸âƒ£ A score out of 10."
    )
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )
    return response.choices[0].message.content.strip()

# ğŸ¯ Start Interview
if st.button("ğŸš€ Start Personalized Interview"):
    st.session_state.current_question = generate_question(topic, experience_level, difficulty, [])
    st.session_state.answer_submitted = False
    st.session_state.interview_over = False
    st.session_state.transcript = ""
    st.session_state.question_count = 1
    st.info(f"ğŸ™ï¸ Starting a {difficulty}-level {topic} interview for a {experience_level} candidate...")

# ğŸ’¬ Show question
if st.session_state.current_question and not st.session_state.interview_over:
    st.subheader(f"Question {st.session_state.question_count}")
    st.markdown(f"**{st.session_state.current_question}**")

    answer = st.text_area("ğŸ’¬ Your Answer:", key=f"answer_{st.session_state.question_count}")

    if st.button("Submit Answer"):
        if not answer.strip():
            st.warning("âš ï¸ Please enter your answer before submitting.")
        else:
            with st.spinner("Evaluating your response..."):
                feedback = evaluate_answer(st.session_state.current_question, answer, experience_level)

            # Append to transcript
            st.session_state.transcript += (
                f"Question {st.session_state.question_count}: {st.session_state.current_question}\n\n"
                f"Candidate Answer:\n{answer}\n\n"
                f"Feedback:\n{feedback}\n\n---\n\n"
            )

            # Show feedback
            st.success("âœ… Feedback Received!")
            st.markdown("### ğŸ’¡ Feedback")
            st.markdown(feedback)

            # Move to next question or end
            st.session_state.question_count += 1
            if st.session_state.question_count <= total_questions:
                next_q = generate_question(
                    topic,
                    experience_level,
                    difficulty,
                    st.session_state.transcript,
                )
                st.session_state.current_question = next_q
                st.session_state.answer_submitted = False
            else:
                st.session_state.interview_over = True

# ğŸ End of Interview
if st.session_state.interview_over:
    st.success("ğŸ‰ Interview Completed!")
    st.markdown("### ğŸ“œ Full Interview Transcript")
    st.code(st.session_state.transcript)
    st.download_button(
        "ğŸ“„ Download Interview Transcript",
        st.session_state.transcript,
        file_name=f"{topic.lower()}_interview_transcript.txt",
    )
